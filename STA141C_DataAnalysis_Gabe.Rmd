---
title: "Data Analysis"
output: html_notebook
---

## Libraries

```{r}
list.of.packages <- c("MASS", "dplyr", "tidyverse", "ggplot2", "leaps", "boot", 
                      "knitr", "hrbrthemes", "RColorBrewer", "paletteer", 
                      "glmnet")
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[,"Package"])]
if(length(new.packages)) install.packages(new.packages)
```

## Load Data

```{r}
set.seed(39)
test <- read.csv("test.csv")
train <- read.csv("train.csv")
test$SalePrice <- rep(NA, length(test$Id))
data <- rbind(train, test)
```

```{r}
# Get rid of MSSubclass because it's qualitative
# Exclude LowQualFinSF, BsmtHalfBath because of primarily zeros
train_quant <- train%>%
  select(where(is.integer) | where(is.double))%>%
  select(-"MSSubClass", -"LowQualFinSF", -"BsmtHalfBath")

train_qual <- train%>%
  select(!where(is.integer) & !where(is.double))
```


## Converting rating variables to numeric

OverallQual & OverallCond

```{r}
# Ten possible ratings
data <- mutate(data, OverallQual = OverallQual / 10)
data <- mutate(data, OverallCond = OverallCond / 10)
```

ExterCond & ExterQual

```{r}
# Five possible ratings
ratings <- c("Po", "Fa", "TA", "Gd", "Ex")
data <- mutate(data, ExterCond = match(c(ExterCond), ratings)/length(ratings))
data <- mutate(data, ExterQual = match(c(ExterQual), ratings)/length(ratings))
```

BsmtQual & BsmtCond

```{r}
ratings <- c("NA", "Po", "Fa", "TA", "Gd", "Ex")
data <- mutate(data, BsmtQual = (match(c(BsmtQual), ratings) - 1)/(length(ratings)-1))
data <- mutate(data, BsmtCond = (match(c(BsmtCond), ratings) - 1)/(length(ratings)-1))
```

BsmtExposure

```{r}
ratings <- c("NA", "No", "Mn", "Av", "Gd")
data <- mutate(data, BsmtExposure = (match(c(BsmtExposure), ratings) - 1)/(length(ratings)-1))
```

BsmtFinType1 & BsmtFinType2

```{r}
ratings <- c("NA", "Unf", "LwQ", "Rec", "BLQ", "ALQ", "GLQ")
data <- mutate(data, BsmtFinType1 = (match(c(BsmtFinType1), ratings) - 1)/(length(ratings)-1))
data <- mutate(data, BsmtFinType2 = (match(c(BsmtFinType2), ratings) - 1)/(length(ratings)-1))
```

HeatingQC

```{r}
ratings <- c("Po", "Fa", "TA", "Gd", "Ex")
data <- mutate(data, HeatingQC = (match(c(HeatingQC), ratings))/(length(ratings)))
```

KitchenQual

```{r}
ratings <- c("Po", "Fa", "TA", "Gd", "Ex")
data <- mutate(data, KitchenQual = (match(c(KitchenQual), ratings))/(length(ratings)))
```

Functional

```{r}
ratings <- c("Sal", "Sev", "Maj2", "Maj1", "Mod", "Min2", "Min1", "Typ")
data <- mutate(data, Functional = (match(c(Functional), ratings))/(length(ratings)))
```

FireplaceQu

```{r}
ratings <- c("NA", "Po", "Fa", "TA", "Gd", "Ex")
data <- mutate(data, FireplaceQu = (match(c(FireplaceQu), ratings) - 1)/(length(ratings)-1))
```

GarageFinish

```{r}
ratings <- c("NA", "Unf", "RFn", "Fin")
data <- mutate(data, GarageFinish = (match(c(GarageFinish), ratings) - 1)/(length(ratings)-1))
```

GarageQual & GarageCond

```{r}
ratings <- c("NA", "Po", "Fa", "TA", "Gd", "Ex")
data <- mutate(data, GarageQual = (match(c(GarageQual), ratings) - 1)/(length(ratings)-1))
data <- mutate(data, GarageCond = (match(c(GarageCond), ratings) - 1)/(length(ratings)-1))
```

PoolQC

```{r}
ratings <- c("NA", "Fa", "TA", "Gd", "Ex")
data <- mutate(data, PoolQC = (match(c(PoolQC), ratings) - 1)/(length(ratings))-1)
```

Fence

```{r}
ratings <- c("NA", "MnWw", "GdWo", "MnPrv", "GdPrv")
data <- mutate(data, Fence = (match(c(Fence), ratings) - 1)/(length(ratings))-1)
```

Splitting Data again

```{r}
test_ratings <- data%>%
  filter(is.na(SalePrice))

train_ratings <- data%>%
  filter(!is.na(SalePrice))
```

## Forward & Backward Selection

```{r}
fit.fwd <- leaps::regsubsets(SalePrice ~ ., train_quant, method="forward")
fit.bwd <- leaps::regsubsets(SalePrice ~ ., train_quant, method="backward")

kable(coef(fit.fwd, 9), caption="Forward Selection")
kable(coef(fit.bwd, 9), caption="Backward Elimination")
```

Cross Validation

```{r}
predict.regsubsets <- function(object, newdata, id, ...) {
  form <- as.formula(object$call[[2]])
  mat <- model.matrix(form, newdata)
  coefi <- coef(object, id = id)
  xvars <- names(coefi)
  mat[, xvars] %*% coefi
}

# Set up LOOCV
n <- nrow(train_quant)
k <- n
folds <- sample(rep(1:k, length = n))
cv.errors <- matrix(NA, k, 9, dimnames = list(NULL, paste(1:9)))
```

```{r}
# Forward Selection
for (tmpFold in 1:k) {
  best.fit <- leaps::regsubsets(SalePrice ~ .,
       data = train_quant[folds != tmpFold, ],
       method = "forward",
       nvmax = 9)
  for (i in 1:9) {
    pred <- predict.regsubsets(best.fit, train_quant[folds == tmpFold, ], 
                               id = i)
    cv.errors[tmpFold, i] <-
         mean((train_quant$SalePrice[folds == tmpFold] - pred)^2)
   }
}

mean.cv.errors <- apply(cv.errors, 2, mean, na.rm=T)
ggplot(data=data.frame(errors=mean.cv.errors), aes(x=1:9, y=errors))+
  geom_point(shape=1, size=3)+
  geom_line()+
  theme_minimal()+
  theme(panel.background = element_rect(fill="#e2ddd4", color = "#e2ddd4", 
                                        size = 0.5, linetype = "solid"))+
  labs(title="Forward Selection MSE for # of params",
       x="Number of Parameters")
```
```{r}
kable(names(coef(fit.fwd, 8))[2:9], caption="Selected Parameters")
```


```{r}
# Backward Elimination
for (tmpFold in 1:k) {
  best.fit <- leaps::regsubsets(SalePrice ~ .,
       data = train_quant[folds != tmpFold, ],
       method = "backward",
       nvmax = 9)
  for (i in 1:9) {
    pred <- predict.regsubsets(best.fit, train_quant[folds == tmpFold, ], 
                               id = i)
    cv.errors[tmpFold, i] <-
         mean((train_quant$SalePrice[folds == tmpFold] - pred)^2)
   }
}

mean.cv.errors <- apply(cv.errors, 2, mean, na.rm=T)
ggplot(data=data.frame(errors=mean.cv.errors), aes(x=1:9, y=errors))+
  geom_point(shape=1, size=3)+
  geom_line()+
  theme_minimal()+
  theme(panel.background = element_rect(fill="#e2ddd4", color = "#e2ddd4", 
                                        size = 0.5, linetype = "solid"))+
  labs(title="Backward Selection MSE for # of params",
       x="Number of Parameters")
kable(names(coef(fit.bwd, 6))[2:7], caption="Selected Parameters")
```

```{r}
kable(names(coef(fit.bwd, 8))[2:9], caption="Selected Parameters")
```

## Ridge and Lasso (NOT WORKING)

```{r}
# Ridge
set.seed(39)
x <- model.matrix(SalePrice ~ ., train_quant)[, -1]
y <- train_quant$SalePrice
train_i <- sample(1:nrow(x), nrow(x) / 2)
test_i <- (-train_i)
y.test <- y[test_i]
grid <- 10^seq(10, -2, length = 100)
cv.out <- cv.glmnet(x[train_i, ], y[train_i], alpha = 0) # 10-fold CV by default 
plot(cv.out)

bestlam <- cv.out$lambda.min
ridge.mod <- glmnet(x[train_i, ], y[train_i], alpha = 0, lambda = grid)
plot(ridge.mod, xvar = "lambda")

ridge.pred <- predict(ridge.mod, s = bestlam,
    newx = x[test_i, ])
mean((ridge.pred - y.test)^2)
```

```{r}
# Lasso
lasso.mod <- glmnet(x[train_i, ], y[train_i], alpha = 1, lambda = grid)
cv.out <- cv.glmnet(x[train_i, ], y[train_i], alpha = 1) # 10-fold CV by default 
plot(cv.out)
bestlam <- cv.out$lambda.min
plot(lasso.mod, xvar = "lambda")
```

```{r}
out <- glmnet(x[train_i, ], y[train_i], alpha = 1, lambda = grid) 
lasso.coef <- predict(out, type = "coefficients",
    s = bestlam)[1:20, ]
lasso.coef # sparse estimates: 8 of them are 0
lasso.coef[lasso.coef != 0]
```

## Exploratory Graphs

```{r}
train_quant%>%
  ggplot(aes(x=as.factor(TotRmsAbvGrd), y=GrLivArea))+
  geom_boxplot(show.legend=F, fill="#55524f")+
  theme_minimal()+
  theme(panel.background = element_rect(fill="#e2ddd4", color = "#e2ddd4", 
                                        size = 0.5, linetype = "solid"))+
  labs(x="# Rooms Above Ground", y="Above Ground Living Area Sqft")
```

```{r}
train_quant%>%
  ggplot(aes(x=as.factor(GarageCars), y=GarageArea))+
  geom_boxplot(show.legend=F, fill="#55524f")+
  theme_minimal()+
  theme(panel.background = element_rect(fill="#e2ddd4", color = "#e2ddd4", 
                                        size = 0.5, linetype = "solid"))+
  labs(x="Garage Car Capacity", y="Garage Sqft")
```

```{r}
train_quant%>%
  ggplot(aes(x=X1stFlrSF, y=TotalBsmtSF))+
  geom_point(show.legend=F)+
  geom_smooth(method="lm")+
  theme_minimal()+
  theme(panel.background = element_rect(fill="#e2ddd4", color = "#e2ddd4", 
                                        size = 0.5, linetype = "solid"))+
  labs(x="First Floor Sqft", y="Basement Sqft")
```

```{r}
train%>%
  ggplot(aes(x=as.factor(MSSubClass)))+
  geom_bar(fill="#55524f")+
  coord_flip()+
  theme_minimal()+
  theme(panel.background = element_rect(fill="#e2ddd4", color = "#e2ddd4", 
                                        size = 0.5, linetype = "solid"))+
  labs(x="Type of Housing", y="count")
```

```{r}
train%>%
  ggplot(aes(x=X1stFlrSF))+
  geom_density(size=0.8)+
  theme_minimal()+
  theme(panel.background = element_rect(fill="#e2ddd4", color = "#e2ddd4", 
                                        size = 0.5, linetype = "solid"))+
  labs(x="First Floor Sqft", y="Density")
```

```{r}
train%>%
  ggplot(aes(x=SalePrice))+
  geom_density(size=0.8)+
  theme_minimal()+
  theme(panel.background = element_rect(fill="#e2ddd4", color = "#e2ddd4", 
                                        size = 0.5, linetype = "solid"))+
  labs(x="Sale Price", y="Density")
```

```{r}
train%>% #<change>
  ggplot(aes(sample=train$SalePrice))+
  geom_qq(color="#55524f", size=1.3)+
  geom_qq_line()+
  theme_minimal()+
  theme(panel.background = element_rect(fill="#e2ddd4", color = "#e2ddd4", 
                                        size = 0.5, linetype = "solid"))+
  labs(title=paste("Sale Price", "QQ Plot"),
       x="Theoretical Quantiles",
       y="Sample Quantiles")
```
